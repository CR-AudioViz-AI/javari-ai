// app/api/javari/router/route.ts
import { NextRequest } from 'next/server';
import { getProvider, getProviderApiKey } from '@/lib/javari/providers';
import { RouterRequest, StreamEvent } from '@/lib/javari/router/types';

export const runtime = 'edge';
export const maxDuration = 25;

// Optimize prompts to avoid slow OpenAI responses
function optimizePrompt(message: string): string {
  let optimized = message;
  
  // Replace words that trigger slow OpenAI responses
  optimized = optimized.replace(/\bcreate\s+a\s+/gi, 'build a ');
  optimized = optimized.replace(/\bmake\s+a\s+/gi, 'develop a ');
  optimized = optimized.replace(/\bcreate\s+an\s+/gi, 'build an ');
  optimized = optimized.replace(/\bmake\s+an\s+/gi, 'develop an ');
  
  return optimized;
}

export async function POST(req: NextRequest) {
  const encoder = new TextEncoder();
  
  const stream = new ReadableStream({
    async start(controller) {
      try {
        const body: RouterRequest = await req.json();
        let { message, mode, provider: requestedProvider } = body;

        if (!message) {
          sendEvent(controller, encoder, {
            type: 'error',
            data: { message: 'Message required' }
          });
          controller.close();
          return;
        }

        // Optimize prompt to avoid slow responses
        message = optimizePrompt(message);

        // All modes use single AI (council disabled due to timeout issues)
        const providerName = requestedProvider || 'openai';
        
        let apiKey: string;
        try {
          apiKey = getProviderApiKey(providerName);
        } catch (error: any) {
          sendEvent(controller, encoder, {
            type: 'error',
            data: { message: `Provider ${providerName} not configured` }
          });
          controller.close();
          return;
        }

        const provider = getProvider(providerName, apiKey);

        try {
          let fullResponse = '';
          
          for await (const chunk of provider.generateStream(message)) {
            fullResponse += chunk;
            sendEvent(controller, encoder, { type: 'token', data: chunk });
          }

          sendEvent(controller, encoder, {
            type: 'final',
            data: { 
              response: fullResponse, 
              provider: providerName, 
              model: provider.getModel(), 
              mode 
            }
          });

        } catch (streamError: any) {
          sendEvent(controller, encoder, {
            type: 'error',
            data: { message: 'Stream error', details: streamError.message }
          });
        }

      } catch (error: any) {
        sendEvent(controller, encoder, {
          type: 'error',
          data: { message: 'Server error', details: error.message }
        });
      } finally {
        controller.close();
      }
    }
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}

function sendEvent(
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder,
  event: StreamEvent
) {
  const data = `data: ${JSON.stringify(event)}\n\n`;
  controller.enqueue(encoder.encode(data));
}

export async function GET() {
  return Response.json({
    status: 'healthy',
    version: '4.5-PROMPT-OPTIMIZED',
    modes: ['single', 'super', 'advanced', 'roadmap'],
    note: 'All modes use single AI with prompt optimization',
    timestamp: new Date().toISOString()
  });
}
